"""
Task worker pipeline for executing claimed tasks through planning, building, and review stages.

Orchestrates git worktrees, docker containers, and OpenCode commands to execute tasks
from claim through completion or failure. Handles error reporting and state persistence.
"""

import os
import re
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, Tuple

try:
    from orchestration.queue_store import QueueStore, TaskRecord
    from orchestration.task_files import (
        parse_frontmatter_optional,
        TaskFileError,
    )
    from orchestration.runtime_git import (
        create_worktree,
        remove_worktree,
        GitRuntimeError,
    )
    from orchestration.runtime_docker import (
        reserve_port,
        launch_container,
        cleanup_task_containers,
        ContainerConfig,
        PortAllocationError,
        ContainerError,
    )
    from orchestration.runtime_opencode import (
        run_make_plan,
        run_execute_plan,
        validate_endpoint,
        PlanError,
        BuildError,
        OpenCodeException,
    )
except ImportError:
    from queue_store import QueueStore, TaskRecord
    from task_files import parse_frontmatter_optional, TaskFileError
    from runtime_git import (
        create_worktree,
        remove_worktree,
        GitRuntimeError,
    )
    from runtime_docker import (
        reserve_port,
        launch_container,
        cleanup_task_containers,
        ContainerConfig,
        PortAllocationError,
        ContainerError,
    )
    from runtime_opencode import (
        run_make_plan,
        run_execute_plan,
        validate_endpoint,
        PlanError,
        BuildError,
        OpenCodeException,
    )


logger = logging.getLogger(__name__)

DEFAULT_DOCKER_IMAGE = "ghcr.io/anomalyco/opencode:latest"
DEFAULT_OPENCODE_SERVER_CMD = ["serve", "--hostname", "0.0.0.0", "--port", "8000"]


# ============================================================================
# Exceptions
# ============================================================================


class WorkerError(Exception):
    """Base exception for worker pipeline errors."""

    pass


class TaskProcessingError(WorkerError):
    """Raised when task processing fails at a specific stage."""

    def __init__(
        self,
        stage: str,
        task_id: str,
        message: str,
        command: str = "",
        exit_code: int = -1,
        stdout: str = "",
        stderr: str = "",
    ):
        self.stage = stage
        self.task_id = task_id
        self.message = message
        self.command = command
        self.exit_code = exit_code
        self.stdout = stdout
        self.stderr = stderr
        super().__init__(f"[{stage}] {message}")


# ============================================================================
# Error Reporting
# ============================================================================


def generate_error_report(
    task_record: TaskRecord,
    stage: str,
    command: str,
    exit_code: int,
    stdout: str,
    stderr: str,
) -> str:
    """
    Generate a detailed error report in markdown format.

    Includes task metadata, failure details, and suggested retry action.

    Args:
        task_record: TaskRecord for the failed task.
        stage: Stage where failure occurred (planning, building, etc).
        command: Command that failed (e.g., "make-plan").
        exit_code: Exit code from failed command (-1 for timeout).
        stdout: Standard output from command.
        stderr: Standard error from command.

    Returns:
        Markdown-formatted error report as string.
    """
    timestamp = datetime.utcnow().isoformat()

    # Truncate long output
    stdout_preview = stdout[:500] if stdout else "(empty)"
    stderr_preview = stderr[:500] if stderr else "(empty)"

    report = f"""# Task Failure Report

**Timestamp**: {timestamp}

## Task Metadata

- **Task ID**: {task_record.id}
- **Repository**: {task_record.repo}
- **Base Branch**: {task_record.base}
- **Task File**: {task_record.task_file}
- **Attempt**: {task_record.attempt}
- **Session ID**: {task_record.session_id}

## Failure Details

**Stage**: {stage}  
**Command**: `{command}`  
**Exit Code**: {exit_code}

### Standard Output

```
{stdout_preview}
```

### Standard Error

```
{stderr_preview}
```

## Runtime Context

- **Branch**: {task_record.branch}
- **Worktree**: {task_record.worktree_path}
- **Container**: {task_record.container}
- **Port**: {task_record.port}

## Suggested Actions

1. Check the error output above for specific failure reasons
2. Review task file: `{task_record.task_file}`
3. Inspect worktree if still available: `{task_record.worktree_path}`
4. Increment attempt counter and retry with `claim_first_todo()`

---

*Generated by worker pipeline*
"""
    return report


def write_error_report(
    error_report: str,
    task_id: str,
    errors_dir: Optional[str] = None,
) -> Path:
    """
    Write error report to file in queue/errors directory.

    Uses task_id and timestamp to ensure unique filename.

    Args:
        error_report: Markdown content to write.
        task_id: Task identifier for filename.
        errors_dir: Directory to write to (default: queue/errors).

    Returns:
        Path to written error file.

    Raises:
        OSError: If write fails.
    """
    if errors_dir is None:
        errors_dir = os.path.join(
            os.path.dirname(os.path.dirname(__file__)), "queue", "errors"
        )

    # Ensure directory exists
    Path(errors_dir).mkdir(parents=True, exist_ok=True)

    # Generate unique filename with timestamp
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S_%f")[:19]  # YYYYMMDD_HHMMSS
    filename = f"{task_id}-{timestamp}.md"
    error_path = Path(errors_dir) / filename

    try:
        error_path.write_text(error_report, encoding="utf-8")
        logger.info(f"Error report written to {error_path}")
        return error_path
    except IOError as e:
        logger.error(f"Failed to write error report: {e}")
        raise


# ============================================================================
# Task Processing
# ============================================================================


class TaskProcessor:
    """
    Processes a claimed task record through the full execution pipeline.

    Orchestrates:
    1. Reading task metadata from canonical file
    2. Creating git worktree and branch
    3. Reserving port and launching docker container
    4. Running make-plan (planning stage)
    5. Running execute-plan (building stage)
    6. Persisting success state or error report on failure

    Attributes:
        store: QueueStore instance for persistence.
        session_id: Unique session identifier for this worker.
        docker_image: Docker image to use.
        container_cmd: OpenCode container command used to start headless server.
        container_host: Host for container mapping (default: 127.0.0.1).
    """

    def __init__(
        self,
        store: QueueStore,
        session_id: str,
        docker_image: str = DEFAULT_DOCKER_IMAGE,
        container_cmd: Optional[list[str]] = None,
        container_host: str = "127.0.0.1",
    ):
        """
        Initialize task processor.

        Args:
            store: QueueStore instance.
            session_id: Unique session identifier.
            docker_image: Docker image name.
            container_cmd: Command args to run inside container.
            container_host: Host for container port mapping (default: 127.0.0.1).
        """
        self.store = store
        self.session_id = session_id
        self.docker_image = docker_image
        self.container_cmd = container_cmd or list(DEFAULT_OPENCODE_SERVER_CMD)
        self.container_host = container_host

        logger.info(f"TaskProcessor initialized with session {session_id}")

    def process_task(self, record: TaskRecord) -> TaskRecord:
        """
        Process a claimed task record through full pipeline.

        Transitions task through stages:
        - planning: read task, setup worktree
        - building: run make-plan, then execute-plan
        - review: on success, persist runtime handles
        - failed: on error, generate error report

        Args:
            record: Claimed TaskRecord (status should be "planning").

        Returns:
            Updated TaskRecord after processing.

        Raises:
            TaskProcessingError: On pipeline failure at any stage.
        """
        logger.info(f"Starting task processing for {record.id}")

        try:
            # Stage 1: Read task and setup git/docker
            self._stage_setup(record)

            # Stage 2: Run planning and building
            self._stage_execute(record)

            # Stage 3: Success - transition to review
            record = self._stage_success(record)

            logger.info(f"Task {record.id} completed successfully")
            return record

        except TaskProcessingError as e:
            logger.error(f"Task {record.id} processing failed: {e}")
            return self._stage_failure(record, e)

    def _stage_setup(self, record: TaskRecord) -> None:
        """
        Setup stage: read task file, create worktree and branch, launch container.

        Updates record with derived values:
        - branch: derived from task_id
        - worktree_path: deterministic path
        - port: reserved port
        - container: container ID

        Args:
            record: TaskRecord to setup (status=planning).

        Raises:
            TaskProcessingError: On setup failure.
        """
        logger.info(f"[setup] Starting setup for {record.id}")

        try:
            # Read task body (frontmatter optional)
            logger.debug(f"Reading task file: {record.task_file}")
            task_body = self._read_task_body(record.task_file)
            logger.debug(f"Task body length: {len(task_body)} chars")

            # Use stored branch if present, otherwise derive from task_id
            branch_name = record.branch or self._derive_branch_name(record.id)
            record.branch = branch_name

            # Require precomputed worktree path from task record
            if not record.worktree_path:
                raise TaskProcessingError(
                    stage="setup",
                    task_id=record.id,
                    message="Missing required worktree_path in task record",
                )

            worktree_path = record.worktree_path
            logger.debug(f"Worktree path: {worktree_path}")

            # Create worktree and branch
            logger.info(f"Creating worktree at {worktree_path}")
            created_path = create_worktree(
                record.repo, worktree_path, branch_name, record.base
            )
            record.worktree_path = created_path
            logger.info(f"Worktree created: {created_path}")

            # Reserve port for container
            logger.debug("Reserving port for container")
            port = reserve_port()
            record.port = port
            logger.debug(f"Reserved port: {port}")

            # Launch container
            logger.info(f"Launching container on port {port}")
            config = ContainerConfig(
                task_id=record.id,
                image=self.docker_image,
                worktree_path=record.worktree_path,
                port=port,
                name=self._derive_container_name(record),
                cmd=self.container_cmd,
            )
            container_id = launch_container(config)
            record.container = container_id
            logger.info(f"Container launched: {container_id}")

            # Update status to building (after successful setup)
            record.status = "building"
            record = self.store.update_record(record.id, record.to_dict())
            logger.info(f"Status transitioned to building for {record.id}")

        except (TaskFileError, GitRuntimeError) as e:
            raise TaskProcessingError(
                stage="setup",
                task_id=record.id,
                message=str(e),
            )
        except (PortAllocationError, ContainerError) as e:
            raise TaskProcessingError(
                stage="setup",
                task_id=record.id,
                message=str(e),
            )

    def _stage_execute(self, record: TaskRecord) -> None:
        """
        Execute stage: run make-plan and execute-plan on container.

        Reads task body and orchestrates planning and building commands
        through the running container.

        Args:
            record: TaskRecord with worktree and container set.

        Raises:
            TaskProcessingError: On planning or building failure.
        """
        logger.info(f"[execute] Starting execution for {record.id}")

        try:
            # Read task body for planning input
            logger.debug(f"Reading task file for body: {record.task_file}")
            task_body = self._read_task_body(record.task_file)

            # Build endpoint URL
            endpoint = validate_endpoint(self.container_host, record.port)
            logger.debug(f"Validated endpoint: {endpoint}")

            # Run planning stage (make-plan)
            logger.info(f"[execute] Running make-plan on {endpoint}")
            try:
                plan_stdout, plan_stderr = run_make_plan(endpoint, task_body)
                logger.debug(f"make-plan output: {len(plan_stdout)} chars")
            except PlanError as e:
                raise TaskProcessingError(
                    stage="planning",
                    task_id=record.id,
                    message=f"make-plan failed: {e}",
                    command="make-plan",
                    exit_code=e.exit_code,
                    stdout=e.stdout,
                    stderr=e.stderr,
                )

            # Run building stage (execute-plan)
            logger.info(f"[execute] Running execute-plan on {endpoint}")
            try:
                build_stdout, build_stderr = run_execute_plan(endpoint)
                logger.debug(f"execute-plan output: {len(build_stdout)} chars")
            except BuildError as e:
                raise TaskProcessingError(
                    stage="building",
                    task_id=record.id,
                    message=f"execute-plan failed: {e}",
                    command="execute-plan",
                    exit_code=e.exit_code,
                    stdout=e.stdout,
                    stderr=e.stderr,
                )

            logger.info(f"[execute] Execution completed for {record.id}")

        except TaskFileError as e:
            raise TaskProcessingError(
                stage="building",
                task_id=record.id,
                message=f"Failed to read task file: {e}",
            )
        except OpenCodeException as e:
            raise TaskProcessingError(
                stage="building",
                task_id=record.id,
                message=str(e),
            )

    def _stage_success(self, record: TaskRecord) -> TaskRecord:
        """
        Success stage: persist runtime handles and transition to review.

        Updates record:
        - status: review
        - container, port, worktree_path, branch retained for review
        - error_file cleared

        Args:
            record: Completed TaskRecord.

        Returns:
            Updated TaskRecord persisted with review status.

        Raises:
            TaskProcessingError: On persistence failure.
        """
        logger.info(f"[success] Transitioning {record.id} to review")

        try:
            updates = {
                "status": "review",
                "error_file": "",
                "updated_at": datetime.utcnow().isoformat(),
            }
            record = self.store.update_record(record.id, updates)
            logger.info(f"Task {record.id} transitioned to review")
            return record
        except Exception as e:
            raise TaskProcessingError(
                stage="success",
                task_id=record.id,
                message=f"Failed to persist success state: {e}",
            )

    def _stage_failure(
        self,
        record: TaskRecord,
        error: TaskProcessingError,
    ) -> TaskRecord:
        """
        Failure stage: generate error report and clean up resources.

        Generates error markdown, persists it, and transitions task to failed.
        Attempts to clean up container and worktree if possible.

        Args:
            record: TaskRecord that failed.
            error: TaskProcessingError with failure details.

        Returns:
            Updated TaskRecord with status=failed and error_file set.
        """
        logger.info(f"[failure] Processing failure for {record.id}")

        # Generate error report
        error_report = generate_error_report(
            record,
            stage=error.stage,
            command=error.command,
            exit_code=error.exit_code,
            stdout=error.stdout,
            stderr=error.stderr,
        )

        # Write error report to file
        try:
            error_path = write_error_report(error_report, record.id)
            error_file = str(error_path)
            logger.info(f"Error report written to {error_file}")
        except OSError as e:
            logger.error(f"Failed to write error report: {e}")
            error_file = ""

        # Clean up all containers related to this task ID.
        # This handles both known launched containers and stale name conflicts.
        try:
            removed = cleanup_task_containers(record.id)
            if removed:
                logger.info(f"Removed {removed} container(s) for task {record.id}")
        except ContainerError as e:
            logger.warning(f"Failed to cleanup task containers: {e}")

        # Clean up worktree
        if record.worktree_path:
            try:
                logger.info(f"Removing worktree {record.worktree_path}")
                remove_worktree(record.repo, record.worktree_path, force=True)
                logger.info(f"Worktree {record.worktree_path} removed")
            except GitRuntimeError as e:
                logger.warning(f"Failed to remove worktree: {e}")

        # Persist failure state
        try:
            updates = {
                "status": "failed",
                "error_file": error_file,
                "updated_at": datetime.utcnow().isoformat(),
            }
            record = self.store.update_record(record.id, updates)
            logger.info(f"Task {record.id} transitioned to failed")
        except Exception as e:
            logger.error(f"Failed to persist failure state: {e}")

        return record

    @staticmethod
    def _derive_branch_name(task_id: str) -> str:
        """
        Derive branch name from task ID.

        Converts task_id to a valid git branch name.
        Example: "T-001" -> "task/T-001"

        Args:
            task_id: Task identifier (e.g., "T-001").

        Returns:
            Valid git branch name.
        """
        # Simple mapping: prepend "task/" and lowercase
        # Handles special chars by replacing with hyphens
        safe_id = task_id.lower().replace(" ", "-").replace("_", "-")
        return f"task/{safe_id}"

    @staticmethod
    def _derive_container_name(record: TaskRecord) -> str:
        """Derive deterministic container name with task ID and created_at."""
        safe_task_id = re.sub(r"[^a-zA-Z0-9_.-]+", "-", record.id).strip("-")
        safe_task_id = safe_task_id or "task"
        created_compact = TaskProcessor._compact_timestamp(record.created_at)
        return f"task-{safe_task_id}-{created_compact}"

    @staticmethod
    def _compact_timestamp(value: str) -> str:
        """Compact timestamp for container names (YYYYMMDDHHMMSS)."""
        digits = "".join(ch for ch in value if ch.isdigit())
        if len(digits) >= 14:
            return digits[:14]
        if digits:
            return digits
        return "ts"

    @staticmethod
    def _read_task_body(task_file: str) -> str:
        """Read task markdown body from stored task_file path."""
        task_path = Path(task_file).expanduser()
        if not task_path.is_absolute():
            repo_root = Path(__file__).resolve().parent.parent
            task_path = repo_root / task_path

        if not task_path.exists():
            raise TaskFileError(f"Task file not found: {task_path}")

        try:
            content = task_path.read_text(encoding="utf-8")
        except OSError as e:
            raise TaskFileError(f"Failed to read task file: {e}")

        metadata, body = parse_frontmatter_optional(content)
        return body if metadata else content
